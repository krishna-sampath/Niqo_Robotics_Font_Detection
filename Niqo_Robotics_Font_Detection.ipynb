{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "nA8FSoCvOXsS"
      },
      "outputs": [],
      "source": [
        "fonts = [\n",
        "    \"Oswald\", \"Roboto\", \"Open Sans\", \"Ubuntu\", \"PT Serif\",\n",
        "    \"Dancing Script\", \"Fredoka One\", \"Arimo\", \"Noto Sans\", \"Patua One\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZudtTyXPuRn"
      },
      "source": [
        "**1. DATA GENERATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "loKZ12AKN3Ya"
      },
      "outputs": [],
      "source": [
        "# Data Generation\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "fonts_dir = '/home/krishna/Documents/Niqo_Robotics/Font_Detection/fonts/'  # Directory containing .ttf font files\n",
        "output_dir = '/home/krishna/Documents/Niqo_Robotics/Font_Detection/generated_images/'  # Directory to save generated images\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Image generation parameters\n",
        "num_images = 1000\n",
        "image_width, image_height = 128, 128\n",
        "\n",
        "fonts = [\n",
        "    \"Arimo-Regular\", \"DancingScript-Regular\", \"FredokaOne-Regular\", \"NotoSans-Regular\", \"OpenSans-Regular\",\n",
        "    \"Oswald\", \"PTSerif-Regular\", \"PatuaOne-Regular\", \"Roboto\", \"Ubuntu-Regular\"\n",
        "]\n",
        "\n",
        "for i in range(num_images):\n",
        "    # Create a white background image\n",
        "    img = Image.new('RGB', (image_width, image_height), color='white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Randomly decide how many instances of \"Hello, World!\" to add (1 to 2)\n",
        "    num_instances = random.randint(1, 2)\n",
        "    annotations = []\n",
        "\n",
        "    for _ in range(num_instances):\n",
        "        # Randomly select a font\n",
        "        font_name = random.choice(fonts)\n",
        "        font_path = os.path.join(fonts_dir, f\"{font_name}.ttf\")\n",
        "        font_size = random.randint(12, 20)  # Adjusted font size\n",
        "        font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "        # Text properties\n",
        "        text = \"Hello, World!\"\n",
        "\n",
        "        # Calculate text size using textbbox\n",
        "        bbox = draw.textbbox((0, 0), text, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        # Random position\n",
        "        max_x = image_width - text_width\n",
        "        max_y = image_height - text_height\n",
        "        if max_x <= 0 or max_y <= 0:\n",
        "            continue  # Skip if text doesn't fit\n",
        "        x = random.randint(0, max_x)\n",
        "        y = random.randint(0, max_y)\n",
        "\n",
        "        # Draw text\n",
        "        draw.text((x, y), text, font=font, fill='black')\n",
        "\n",
        "        # Save annotation (bounding box and font)\n",
        "        bbox = [x, y, x + text_width, y + text_height]\n",
        "        annotations.append({'bbox': bbox, 'font': font_name})\n",
        "\n",
        "    if not annotations:\n",
        "        continue  # Skip saving if no annotations\n",
        "\n",
        "    # Save image\n",
        "    image_path = os.path.join(output_dir, f\"image_{i}.png\")\n",
        "    img.save(image_path)\n",
        "\n",
        "    # Save annotations\n",
        "    annotation_path = os.path.join(output_dir, f\"image_{i}.txt\")\n",
        "    with open(annotation_path, 'w') as f:\n",
        "        for ann in annotations:\n",
        "            bbox = ann['bbox']\n",
        "            font_name = ann['font']\n",
        "            f.write(f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]},{font_name}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw0XTyNePzWB"
      },
      "source": [
        "**DATA ANNOTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "RXKezL5RP2ta"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# Get all annotation files\n",
        "annotation_files = glob.glob(os.path.join(output_dir, '*.txt'))\n",
        "\n",
        "data = []\n",
        "\n",
        "for ann_file in annotation_files:\n",
        "    image_name = os.path.basename(ann_file).replace('.txt', '.png')\n",
        "    image_path = os.path.join(output_dir, image_name)\n",
        "    with open(ann_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            x_min, y_min, x_max, y_max, font_name = line.strip().split(',')\n",
        "            data.append([image_path, int(x_min), int(y_min), int(x_max), int(y_max), font_name])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=['image_path', 'x_min', 'y_min', 'x_max', 'y_max', 'font_label'])\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('/home/krishna/Documents/Niqo_Robotics/Font_Detection/annotations.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpZgpgz8P78u"
      },
      "source": [
        "**Model Architecture Design**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "1Hy-PX6UP6YO"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "j4bWUSryQDlg"
      },
      "outputs": [],
      "source": [
        "class HelloWorldDataset(Dataset):\n",
        "    def __init__(self, annotations_file, transform=None):\n",
        "        self.annotations = pd.read_csv(annotations_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Encode font labels\n",
        "        self.fonts = [\n",
        "            \"Arimo-Regular\", \"DancingScript-Regular\", \"FredokaOne-Regular\", \"NotoSans-Regular\", \"OpenSans-Regular\",\n",
        "            \"Oswald\", \"PTSerif-Regular\", \"PatuaOne-Regular\", \"Roboto\", \"Ubuntu-Regular\"\n",
        "        ]\n",
        "        self.font_to_idx = {font: idx for idx, font in enumerate(self.fonts)}\n",
        "\n",
        "        # Group annotations by image\n",
        "        self.image_annotations = self.annotations.groupby('image_path')\n",
        "\n",
        "        # Get list of image paths\n",
        "        self.image_paths = self.annotations['image_path'].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        records = self.image_annotations.get_group(image_path)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for _, record in records.iterrows():\n",
        "            bbox = [record['x_min'], record['y_min'], record['x_max'], record['y_max']]\n",
        "            boxes.append(bbox)\n",
        "            labels.append(self.font_to_idx[record['font_label']])\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "        return image, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "ldODbPrKQG0V"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)), \n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "nNXEz6TOQJb2"
      },
      "outputs": [],
      "source": [
        "class CNNBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNBackbone, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "tdVXmtXxQNMN"
      },
      "outputs": [],
      "source": [
        "class RPN(nn.Module):\n",
        "    def __init__(self, in_channels, num_anchors_per_location):\n",
        "        super(RPN, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, 256, kernel_size=3, padding=1)\n",
        "        self.objectness = nn.Conv2d(256, num_anchors_per_location, kernel_size=1)\n",
        "        self.regressor = nn.Conv2d(256, num_anchors_per_location * 4, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv(x))\n",
        "        objectness = torch.sigmoid(self.objectness(x))  \n",
        "        bbox_deltas = self.regressor(x)  \n",
        "        return objectness, bbox_deltas\n",
        "\n",
        "class FontClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(FontClassifier, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.mean([2, 3])  # Global average pooling\n",
        "        return x\n",
        "\n",
        "class HelloWorldDetector(nn.Module):\n",
        "    def __init__(self, num_classes, num_anchors_per_location):\n",
        "        super(HelloWorldDetector, self).__init__()\n",
        "        self.backbone = CNNBackbone()\n",
        "        self.rpn = RPN(in_channels=32, num_anchors_per_location=num_anchors_per_location)\n",
        "        self.font_classifier = FontClassifier(in_channels=32, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.backbone(images)\n",
        "        objectness, bbox_deltas = self.rpn(features)\n",
        "        font_scores = self.font_classifier(features)\n",
        "        return objectness, bbox_deltas, font_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKpptBONQZI8"
      },
      "source": [
        "**TRAINING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "XEd9ISBdSJ8P"
      },
      "outputs": [],
      "source": [
        "def generate_anchors(feature_map_size, scales, ratios):\n",
        "    anchors = []\n",
        "    grid_height, grid_width = feature_map_size\n",
        "    for y in range(grid_height):\n",
        "        for x in range(grid_width):\n",
        "            center_x = x + 0.5\n",
        "            center_y = y + 0.5\n",
        "            for scale in scales:\n",
        "                for ratio in ratios:\n",
        "                    w = scale * np.sqrt(ratio)\n",
        "                    h = scale / np.sqrt(ratio)\n",
        "                    anchors.append([\n",
        "                        center_x - w / 2,\n",
        "                        center_y - h / 2,\n",
        "                        center_x + w / 2,\n",
        "                        center_y + h / 2\n",
        "                    ])\n",
        "    return torch.tensor(anchors, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "r7fNPauJSLKg"
      },
      "outputs": [],
      "source": [
        "def compute_iou(anchors, gt_boxes):\n",
        "    num_anchors = anchors.size(0)\n",
        "    num_gt_boxes = gt_boxes.size(0)\n",
        "    ious = torch.zeros(num_anchors, num_gt_boxes)\n",
        "    for i in range(num_anchors):\n",
        "        anchor = anchors[i]\n",
        "        anchor_area = (anchor[2] - anchor[0]) * (anchor[3] - anchor[1])\n",
        "        for j in range(num_gt_boxes):\n",
        "            gt = gt_boxes[j]\n",
        "            inter_x1 = max(anchor[0], gt[0])\n",
        "            inter_y1 = max(anchor[1], gt[1])\n",
        "            inter_x2 = min(anchor[2], gt[2])\n",
        "            inter_y2 = min(anchor[3], gt[3])\n",
        "            if inter_x1 < inter_x2 and inter_y1 < inter_y2:\n",
        "                inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)\n",
        "                gt_area = (gt[2] - gt[0]) * (gt[3] - gt[1])\n",
        "                union_area = anchor_area + gt_area - inter_area\n",
        "                ious[i, j] = inter_area / union_area\n",
        "    return ious\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "lr4IeiRtSNFP"
      },
      "outputs": [],
      "source": [
        "def assign_labels(anchors, gt_boxes, gt_labels, iou_threshold=0.5):\n",
        "    ious = compute_iou(anchors, gt_boxes)\n",
        "    max_iou, max_iou_idx = ious.max(dim=1)\n",
        "    labels = torch.full((anchors.size(0),), -1, dtype=torch.int64)  # -1 means ignore\n",
        "    # Positive anchors\n",
        "    positive_indices = max_iou >= iou_threshold\n",
        "    labels[positive_indices] = gt_labels[max_iou_idx[positive_indices]]\n",
        "    # Negative anchors\n",
        "    negative_indices = max_iou < 0.1\n",
        "    labels[negative_indices] = 0  # Background class\n",
        "    # Bounding box regression targets\n",
        "    bbox_targets = torch.zeros_like(anchors)#, dtype=gt_boxes.dtype)\n",
        "    bbox_targets[positive_indices] = gt_boxes[max_iou_idx[positive_indices]]\n",
        "    return labels, bbox_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "m-_jExr4QbXE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Epoch [1/10], Batch [1/250], Loss: 12.0229, Obj Loss: 2.8194, BBox Loss: 0.0049, Class Loss: 9.1986\n",
            "Epoch [1/10], Batch [11/250], Loss: 11.4442, Obj Loss: 1.7274, BBox Loss: 0.0046, Class Loss: 9.7121\n",
            "Epoch [1/10], Batch [21/250], Loss: 11.1139, Obj Loss: 1.4243, BBox Loss: 0.0029, Class Loss: 9.6867\n",
            "Epoch [1/10], Batch [31/250], Loss: 10.4749, Obj Loss: 1.2795, BBox Loss: 0.0017, Class Loss: 9.1938\n",
            "Epoch [1/10], Batch [41/250], Loss: 10.0720, Obj Loss: 1.0966, BBox Loss: 0.0010, Class Loss: 8.9744\n",
            "Epoch [1/10], Batch [51/250], Loss: 11.3329, Obj Loss: 1.5960, BBox Loss: 0.0006, Class Loss: 9.7363\n",
            "Epoch [1/10], Batch [61/250], Loss: 10.9681, Obj Loss: 2.1354, BBox Loss: 0.0004, Class Loss: 8.8323\n",
            "Epoch [1/10], Batch [71/250], Loss: 9.9623, Obj Loss: 0.7382, BBox Loss: 0.0002, Class Loss: 9.2240\n",
            "Epoch [1/10], Batch [81/250], Loss: 10.4862, Obj Loss: 0.8658, BBox Loss: 0.0003, Class Loss: 9.6201\n",
            "Epoch [1/10], Batch [91/250], Loss: 10.2564, Obj Loss: 1.1903, BBox Loss: 0.0002, Class Loss: 9.0660\n",
            "Epoch [1/10], Batch [101/250], Loss: 11.0824, Obj Loss: 2.0979, BBox Loss: 0.0002, Class Loss: 8.9844\n",
            "Epoch [1/10], Batch [111/250], Loss: 10.5668, Obj Loss: 1.1963, BBox Loss: 0.0002, Class Loss: 9.3702\n",
            "Epoch [1/10], Batch [121/250], Loss: 11.1360, Obj Loss: 2.0261, BBox Loss: 0.0003, Class Loss: 9.1096\n",
            "Epoch [1/10], Batch [131/250], Loss: 10.9387, Obj Loss: 1.3398, BBox Loss: 0.0001, Class Loss: 9.5987\n",
            "Epoch [1/10], Batch [141/250], Loss: 10.9936, Obj Loss: 1.7490, BBox Loss: 0.0001, Class Loss: 9.2445\n",
            "Epoch [1/10], Batch [151/250], Loss: 10.3001, Obj Loss: 0.9113, BBox Loss: 0.0001, Class Loss: 9.3887\n",
            "Epoch [1/10], Batch [161/250], Loss: 9.5757, Obj Loss: 0.5569, BBox Loss: 0.0002, Class Loss: 9.0186\n",
            "Epoch [1/10], Batch [171/250], Loss: 9.7850, Obj Loss: 0.7607, BBox Loss: 0.0001, Class Loss: 9.0242\n",
            "Epoch [1/10], Batch [181/250], Loss: 10.3015, Obj Loss: 1.4804, BBox Loss: 0.0002, Class Loss: 8.8209\n",
            "Epoch [1/10], Batch [191/250], Loss: 11.1581, Obj Loss: 1.7595, BBox Loss: 0.0002, Class Loss: 9.3985\n",
            "Epoch [1/10], Batch [201/250], Loss: 11.0082, Obj Loss: 1.7680, BBox Loss: 0.0002, Class Loss: 9.2400\n",
            "Epoch [1/10], Batch [211/250], Loss: 10.2628, Obj Loss: 1.4793, BBox Loss: 0.0002, Class Loss: 8.7833\n",
            "Epoch [1/10], Batch [221/250], Loss: 10.2148, Obj Loss: 0.9878, BBox Loss: 0.0002, Class Loss: 9.2268\n",
            "Epoch [1/10], Batch [231/250], Loss: 11.2601, Obj Loss: 2.1638, BBox Loss: 0.0004, Class Loss: 9.0959\n",
            "Epoch [1/10], Batch [241/250], Loss: 10.6327, Obj Loss: 1.2752, BBox Loss: 0.0001, Class Loss: 9.3574\n",
            "Epoch [1/10] completed in 616.47s\n",
            "Epoch [2/10], Batch [1/250], Loss: 9.2605, Obj Loss: 0.4286, BBox Loss: 0.0001, Class Loss: 8.8318\n",
            "Epoch [2/10], Batch [11/250], Loss: 10.3225, Obj Loss: 1.1897, BBox Loss: 0.0002, Class Loss: 9.1326\n",
            "Epoch [2/10], Batch [21/250], Loss: 11.4493, Obj Loss: 2.3441, BBox Loss: 0.0002, Class Loss: 9.1050\n",
            "Epoch [2/10], Batch [31/250], Loss: 10.4414, Obj Loss: 1.2650, BBox Loss: 0.0002, Class Loss: 9.1763\n",
            "Epoch [2/10], Batch [41/250], Loss: 10.9648, Obj Loss: 1.7083, BBox Loss: 0.0002, Class Loss: 9.2563\n",
            "Epoch [2/10], Batch [51/250], Loss: 10.5449, Obj Loss: 1.2234, BBox Loss: 0.0001, Class Loss: 9.3214\n",
            "Epoch [2/10], Batch [61/250], Loss: 10.8814, Obj Loss: 1.6412, BBox Loss: 0.0002, Class Loss: 9.2400\n",
            "Epoch [2/10], Batch [71/250], Loss: 10.6764, Obj Loss: 1.3640, BBox Loss: 0.0002, Class Loss: 9.3122\n",
            "Epoch [2/10], Batch [81/250], Loss: 10.6169, Obj Loss: 1.5083, BBox Loss: 0.0002, Class Loss: 9.1084\n",
            "Epoch [2/10], Batch [91/250], Loss: 10.7107, Obj Loss: 1.3287, BBox Loss: 0.0005, Class Loss: 9.3815\n",
            "Epoch [2/10], Batch [101/250], Loss: 10.5756, Obj Loss: 1.4148, BBox Loss: 0.0004, Class Loss: 9.1604\n",
            "Epoch [2/10], Batch [111/250], Loss: 10.5805, Obj Loss: 1.2596, BBox Loss: 0.0445, Class Loss: 9.2763\n",
            "Epoch [2/10], Batch [121/250], Loss: 10.3637, Obj Loss: 1.1684, BBox Loss: 0.0002, Class Loss: 9.1952\n",
            "Epoch [2/10], Batch [131/250], Loss: 9.8024, Obj Loss: 0.5324, BBox Loss: 0.0002, Class Loss: 9.2698\n",
            "Epoch [2/10], Batch [141/250], Loss: 11.1612, Obj Loss: 1.8858, BBox Loss: 0.0003, Class Loss: 9.2751\n",
            "Epoch [2/10], Batch [151/250], Loss: 11.0111, Obj Loss: 1.8156, BBox Loss: 0.0003, Class Loss: 9.1951\n",
            "Epoch [2/10], Batch [161/250], Loss: 10.3951, Obj Loss: 1.2322, BBox Loss: 0.0006, Class Loss: 9.1623\n",
            "Epoch [2/10], Batch [171/250], Loss: 10.6148, Obj Loss: 1.2651, BBox Loss: 0.0010, Class Loss: 9.3488\n",
            "Epoch [2/10], Batch [181/250], Loss: 10.1092, Obj Loss: 0.9652, BBox Loss: 0.0007, Class Loss: 9.1433\n",
            "Epoch [2/10], Batch [191/250], Loss: 9.3284, Obj Loss: 0.6186, BBox Loss: 0.0011, Class Loss: 8.7088\n",
            "Epoch [2/10], Batch [201/250], Loss: 10.3295, Obj Loss: 1.3384, BBox Loss: 0.0009, Class Loss: 8.9901\n",
            "Epoch [2/10], Batch [211/250], Loss: 11.4595, Obj Loss: 2.2044, BBox Loss: 0.0005, Class Loss: 9.2546\n",
            "Epoch [2/10], Batch [221/250], Loss: 10.1595, Obj Loss: 1.5252, BBox Loss: 0.0007, Class Loss: 8.6336\n",
            "Epoch [2/10], Batch [231/250], Loss: 9.3831, Obj Loss: 0.8980, BBox Loss: 0.0013, Class Loss: 8.4837\n",
            "Epoch [2/10], Batch [241/250], Loss: 10.0621, Obj Loss: 1.2153, BBox Loss: 0.0010, Class Loss: 8.8459\n",
            "Epoch [2/10] completed in 612.60s\n",
            "Epoch [3/10], Batch [1/250], Loss: 9.7941, Obj Loss: 0.4659, BBox Loss: 0.0005, Class Loss: 9.3277\n",
            "Epoch [3/10], Batch [11/250], Loss: 9.2102, Obj Loss: 0.7768, BBox Loss: 0.0005, Class Loss: 8.4329\n",
            "Epoch [3/10], Batch [21/250], Loss: 10.7089, Obj Loss: 1.4561, BBox Loss: 0.0003, Class Loss: 9.2525\n",
            "Epoch [3/10], Batch [31/250], Loss: 10.0309, Obj Loss: 1.2497, BBox Loss: 0.0003, Class Loss: 8.7809\n",
            "Epoch [3/10], Batch [41/250], Loss: 10.1258, Obj Loss: 0.8384, BBox Loss: 0.0003, Class Loss: 9.2870\n",
            "Epoch [3/10], Batch [51/250], Loss: 11.4801, Obj Loss: 1.9159, BBox Loss: 0.0003, Class Loss: 9.5638\n",
            "Epoch [3/10], Batch [61/250], Loss: 10.1921, Obj Loss: 1.3872, BBox Loss: 0.0002, Class Loss: 8.8047\n",
            "Epoch [3/10], Batch [71/250], Loss: 10.0488, Obj Loss: 1.3502, BBox Loss: 0.0003, Class Loss: 8.6983\n",
            "Epoch [3/10], Batch [81/250], Loss: 10.6027, Obj Loss: 1.2623, BBox Loss: 0.0002, Class Loss: 9.3402\n",
            "Epoch [3/10], Batch [91/250], Loss: 10.3624, Obj Loss: 1.6235, BBox Loss: 0.0004, Class Loss: 8.7385\n",
            "Epoch [3/10], Batch [101/250], Loss: 10.3323, Obj Loss: 1.3727, BBox Loss: 0.0002, Class Loss: 8.9594\n",
            "Epoch [3/10], Batch [111/250], Loss: 10.3102, Obj Loss: 1.1626, BBox Loss: 0.0002, Class Loss: 9.1475\n",
            "Epoch [3/10], Batch [121/250], Loss: 10.0539, Obj Loss: 1.1612, BBox Loss: 0.0003, Class Loss: 8.8925\n",
            "Epoch [3/10], Batch [131/250], Loss: 10.9399, Obj Loss: 1.6603, BBox Loss: 0.0006, Class Loss: 9.2790\n",
            "Epoch [3/10], Batch [141/250], Loss: 9.8759, Obj Loss: 1.3619, BBox Loss: 0.0004, Class Loss: 8.5135\n",
            "Epoch [3/10], Batch [151/250], Loss: 10.2339, Obj Loss: 0.9797, BBox Loss: 0.0003, Class Loss: 9.2539\n",
            "Epoch [3/10], Batch [161/250], Loss: 8.5205, Obj Loss: 0.9121, BBox Loss: 0.0004, Class Loss: 7.6079\n",
            "Epoch [3/10], Batch [171/250], Loss: 10.9396, Obj Loss: 1.6446, BBox Loss: 0.0002, Class Loss: 9.2948\n",
            "Epoch [3/10], Batch [181/250], Loss: 11.1668, Obj Loss: 1.9902, BBox Loss: 0.0002, Class Loss: 9.1764\n",
            "Epoch [3/10], Batch [191/250], Loss: 10.4099, Obj Loss: 0.9713, BBox Loss: 0.0002, Class Loss: 9.4384\n",
            "Epoch [3/10], Batch [201/250], Loss: 10.4510, Obj Loss: 1.6336, BBox Loss: 0.0004, Class Loss: 8.8170\n",
            "Epoch [3/10], Batch [211/250], Loss: 9.8783, Obj Loss: 0.9400, BBox Loss: 0.0004, Class Loss: 8.9379\n",
            "Epoch [3/10], Batch [221/250], Loss: 9.5771, Obj Loss: 0.6591, BBox Loss: 0.0002, Class Loss: 8.9178\n",
            "Epoch [3/10], Batch [231/250], Loss: 9.7996, Obj Loss: 0.4843, BBox Loss: 0.0004, Class Loss: 9.3149\n",
            "Epoch [3/10], Batch [241/250], Loss: 12.1700, Obj Loss: 3.2280, BBox Loss: 0.0005, Class Loss: 8.9415\n",
            "Epoch [3/10] completed in 615.81s\n",
            "Epoch [4/10], Batch [1/250], Loss: 9.4477, Obj Loss: 0.9244, BBox Loss: 0.0003, Class Loss: 8.5230\n",
            "Epoch [4/10], Batch [11/250], Loss: 9.5469, Obj Loss: 0.6333, BBox Loss: 0.0002, Class Loss: 8.9134\n",
            "Epoch [4/10], Batch [21/250], Loss: 8.8416, Obj Loss: 0.7986, BBox Loss: 0.0005, Class Loss: 8.0425\n",
            "Epoch [4/10], Batch [31/250], Loss: 11.0283, Obj Loss: 1.4809, BBox Loss: 0.0004, Class Loss: 9.5470\n",
            "Epoch [4/10], Batch [41/250], Loss: 9.9706, Obj Loss: 1.4006, BBox Loss: 0.0445, Class Loss: 8.5255\n",
            "Epoch [4/10], Batch [51/250], Loss: 11.0161, Obj Loss: 1.7702, BBox Loss: 0.0002, Class Loss: 9.2458\n",
            "Epoch [4/10], Batch [61/250], Loss: 9.8554, Obj Loss: 0.7010, BBox Loss: 0.0003, Class Loss: 9.1541\n",
            "Epoch [4/10], Batch [71/250], Loss: 9.8193, Obj Loss: 0.4420, BBox Loss: 0.0002, Class Loss: 9.3770\n",
            "Epoch [4/10], Batch [81/250], Loss: 9.9071, Obj Loss: 1.0257, BBox Loss: 0.0002, Class Loss: 8.8811\n",
            "Epoch [4/10], Batch [91/250], Loss: 9.5602, Obj Loss: 1.3129, BBox Loss: 0.0003, Class Loss: 8.2470\n",
            "Epoch [4/10], Batch [101/250], Loss: 11.6464, Obj Loss: 2.9743, BBox Loss: 0.0005, Class Loss: 8.6716\n",
            "Epoch [4/10], Batch [111/250], Loss: 9.9913, Obj Loss: 0.8755, BBox Loss: 0.0002, Class Loss: 9.1157\n",
            "Epoch [4/10], Batch [121/250], Loss: 10.5702, Obj Loss: 1.5000, BBox Loss: 0.0004, Class Loss: 9.0699\n",
            "Epoch [4/10], Batch [131/250], Loss: 10.6815, Obj Loss: 1.4870, BBox Loss: 0.0003, Class Loss: 9.1942\n",
            "Epoch [4/10], Batch [141/250], Loss: 10.0656, Obj Loss: 1.5211, BBox Loss: 0.0002, Class Loss: 8.5443\n",
            "Epoch [4/10], Batch [151/250], Loss: 7.7565, Obj Loss: 1.0522, BBox Loss: 0.0006, Class Loss: 6.7038\n",
            "Epoch [4/10], Batch [161/250], Loss: 8.8014, Obj Loss: 0.5862, BBox Loss: 0.0004, Class Loss: 8.2149\n",
            "Epoch [4/10], Batch [171/250], Loss: 9.0104, Obj Loss: 0.3451, BBox Loss: 0.0005, Class Loss: 8.6648\n",
            "Epoch [4/10], Batch [181/250], Loss: 11.4086, Obj Loss: 3.0968, BBox Loss: 0.0010, Class Loss: 8.3109\n",
            "Epoch [4/10], Batch [191/250], Loss: 9.7453, Obj Loss: 2.0868, BBox Loss: 0.0008, Class Loss: 7.6577\n",
            "Epoch [4/10], Batch [201/250], Loss: 11.7663, Obj Loss: 1.7939, BBox Loss: 0.0007, Class Loss: 9.9717\n",
            "Epoch [4/10], Batch [211/250], Loss: 9.2411, Obj Loss: 0.5794, BBox Loss: 0.0006, Class Loss: 8.6611\n",
            "Epoch [4/10], Batch [221/250], Loss: 9.5842, Obj Loss: 1.5128, BBox Loss: 0.0006, Class Loss: 8.0708\n",
            "Epoch [4/10], Batch [231/250], Loss: 10.0230, Obj Loss: 1.4266, BBox Loss: 0.0004, Class Loss: 8.5960\n",
            "Epoch [4/10], Batch [241/250], Loss: 8.7222, Obj Loss: 0.8700, BBox Loss: 0.0006, Class Loss: 7.8516\n",
            "Epoch [4/10] completed in 610.06s\n",
            "Epoch [5/10], Batch [1/250], Loss: 8.9859, Obj Loss: 1.5430, BBox Loss: 0.0005, Class Loss: 7.4424\n",
            "Epoch [5/10], Batch [11/250], Loss: 10.7047, Obj Loss: 1.2652, BBox Loss: 0.0005, Class Loss: 9.4390\n",
            "Epoch [5/10], Batch [21/250], Loss: 10.4588, Obj Loss: 1.0802, BBox Loss: 0.0005, Class Loss: 9.3780\n",
            "Epoch [5/10], Batch [31/250], Loss: 9.7044, Obj Loss: 1.1175, BBox Loss: 0.0002, Class Loss: 8.5867\n",
            "Epoch [5/10], Batch [41/250], Loss: 9.0779, Obj Loss: 1.7277, BBox Loss: 0.0006, Class Loss: 7.3497\n",
            "Epoch [5/10], Batch [51/250], Loss: 9.8603, Obj Loss: 1.0109, BBox Loss: 0.0004, Class Loss: 8.8490\n",
            "Epoch [5/10], Batch [61/250], Loss: 8.4543, Obj Loss: 0.5024, BBox Loss: 0.0002, Class Loss: 7.9517\n",
            "Epoch [5/10], Batch [71/250], Loss: 9.9238, Obj Loss: 0.5713, BBox Loss: 0.0002, Class Loss: 9.3522\n",
            "Epoch [5/10], Batch [81/250], Loss: 11.0633, Obj Loss: 1.8915, BBox Loss: 0.0004, Class Loss: 9.1714\n",
            "Epoch [5/10], Batch [91/250], Loss: 9.0750, Obj Loss: 0.7720, BBox Loss: 0.0006, Class Loss: 8.3025\n",
            "Epoch [5/10], Batch [101/250], Loss: 10.3373, Obj Loss: 3.6900, BBox Loss: 0.0007, Class Loss: 6.6466\n",
            "Epoch [5/10], Batch [111/250], Loss: 9.2439, Obj Loss: 1.1550, BBox Loss: 0.0004, Class Loss: 8.0885\n",
            "Epoch [5/10], Batch [121/250], Loss: 10.1698, Obj Loss: 0.7765, BBox Loss: 0.0004, Class Loss: 9.3929\n",
            "Epoch [5/10], Batch [131/250], Loss: 10.2175, Obj Loss: 1.4660, BBox Loss: 0.0004, Class Loss: 8.7512\n",
            "Epoch [5/10], Batch [141/250], Loss: 10.9509, Obj Loss: 2.0219, BBox Loss: 0.0003, Class Loss: 8.9287\n",
            "Epoch [5/10], Batch [151/250], Loss: 9.3361, Obj Loss: 0.5547, BBox Loss: 0.0003, Class Loss: 8.7811\n",
            "Epoch [5/10], Batch [161/250], Loss: 11.8505, Obj Loss: 2.9683, BBox Loss: 0.0003, Class Loss: 8.8820\n",
            "Epoch [5/10], Batch [171/250], Loss: 9.8364, Obj Loss: 1.0091, BBox Loss: 0.0003, Class Loss: 8.8270\n",
            "Epoch [5/10], Batch [181/250], Loss: 9.6418, Obj Loss: 2.1317, BBox Loss: 0.0005, Class Loss: 7.5096\n",
            "Epoch [5/10], Batch [191/250], Loss: 9.3221, Obj Loss: 1.9019, BBox Loss: 0.0004, Class Loss: 7.4198\n",
            "Epoch [5/10], Batch [201/250], Loss: 11.8412, Obj Loss: 1.9154, BBox Loss: 0.0006, Class Loss: 9.9252\n",
            "Epoch [5/10], Batch [211/250], Loss: 10.7781, Obj Loss: 2.1803, BBox Loss: 0.0004, Class Loss: 8.5974\n",
            "Epoch [5/10], Batch [221/250], Loss: 9.3795, Obj Loss: 0.9026, BBox Loss: 0.0006, Class Loss: 8.4764\n",
            "Epoch [5/10], Batch [231/250], Loss: 10.0165, Obj Loss: 1.3654, BBox Loss: 0.0005, Class Loss: 8.6507\n",
            "Epoch [5/10], Batch [241/250], Loss: 9.6171, Obj Loss: 0.8155, BBox Loss: 0.0005, Class Loss: 8.8011\n",
            "Epoch [5/10] completed in 605.10s\n",
            "Epoch [6/10], Batch [1/250], Loss: 8.9930, Obj Loss: 0.9930, BBox Loss: 0.0004, Class Loss: 7.9995\n",
            "Epoch [6/10], Batch [11/250], Loss: 11.2463, Obj Loss: 0.6287, BBox Loss: 0.0006, Class Loss: 10.6170\n",
            "Epoch [6/10], Batch [21/250], Loss: 9.8577, Obj Loss: 1.6139, BBox Loss: 0.0003, Class Loss: 8.2435\n",
            "Epoch [6/10], Batch [31/250], Loss: 9.2298, Obj Loss: 1.2199, BBox Loss: 0.0004, Class Loss: 8.0095\n",
            "Epoch [6/10], Batch [41/250], Loss: 9.4458, Obj Loss: 1.3024, BBox Loss: 0.0004, Class Loss: 8.1431\n",
            "Epoch [6/10], Batch [51/250], Loss: 9.5934, Obj Loss: 0.9570, BBox Loss: 0.0002, Class Loss: 8.6361\n",
            "Epoch [6/10], Batch [61/250], Loss: 10.5743, Obj Loss: 2.6073, BBox Loss: 0.0006, Class Loss: 7.9665\n",
            "Epoch [6/10], Batch [71/250], Loss: 10.0234, Obj Loss: 0.6636, BBox Loss: 0.0003, Class Loss: 9.3595\n",
            "Epoch [6/10], Batch [81/250], Loss: 9.6433, Obj Loss: 0.5262, BBox Loss: 0.0003, Class Loss: 9.1168\n",
            "Epoch [6/10], Batch [91/250], Loss: 9.6783, Obj Loss: 0.7781, BBox Loss: 0.0002, Class Loss: 8.9000\n",
            "Epoch [6/10], Batch [101/250], Loss: 12.6465, Obj Loss: 2.1851, BBox Loss: 0.0007, Class Loss: 10.4608\n",
            "Epoch [6/10], Batch [111/250], Loss: 8.2894, Obj Loss: 1.1133, BBox Loss: 0.0008, Class Loss: 7.1752\n",
            "Epoch [6/10], Batch [121/250], Loss: 11.5426, Obj Loss: 2.5082, BBox Loss: 0.0010, Class Loss: 9.0334\n",
            "Epoch [6/10], Batch [131/250], Loss: 11.0643, Obj Loss: 1.9305, BBox Loss: 0.0005, Class Loss: 9.1333\n",
            "Epoch [6/10], Batch [141/250], Loss: 10.6869, Obj Loss: 1.6802, BBox Loss: 0.0004, Class Loss: 9.0064\n",
            "Epoch [6/10], Batch [151/250], Loss: 8.5684, Obj Loss: 1.4821, BBox Loss: 0.0011, Class Loss: 7.0853\n",
            "Epoch [6/10], Batch [161/250], Loss: 10.4724, Obj Loss: 1.6106, BBox Loss: 0.1919, Class Loss: 8.6698\n",
            "Epoch [6/10], Batch [171/250], Loss: 11.0537, Obj Loss: 2.1450, BBox Loss: 0.0005, Class Loss: 8.9082\n",
            "Epoch [6/10], Batch [181/250], Loss: 9.5417, Obj Loss: 1.9371, BBox Loss: 0.0003, Class Loss: 7.6043\n",
            "Epoch [6/10], Batch [191/250], Loss: 10.6346, Obj Loss: 1.2320, BBox Loss: 0.0004, Class Loss: 9.4022\n",
            "Epoch [6/10], Batch [201/250], Loss: 8.7820, Obj Loss: 2.4282, BBox Loss: 0.0005, Class Loss: 6.3533\n",
            "Epoch [6/10], Batch [211/250], Loss: 9.0691, Obj Loss: 0.8753, BBox Loss: 0.0002, Class Loss: 8.1936\n",
            "Epoch [6/10], Batch [221/250], Loss: 7.9508, Obj Loss: 1.0206, BBox Loss: 0.0003, Class Loss: 6.9299\n",
            "Epoch [6/10], Batch [231/250], Loss: 8.4951, Obj Loss: 1.5252, BBox Loss: 0.0005, Class Loss: 6.9694\n",
            "Epoch [6/10], Batch [241/250], Loss: 8.0532, Obj Loss: 0.7133, BBox Loss: 0.0003, Class Loss: 7.3396\n",
            "Epoch [6/10] completed in 631.29s\n",
            "Epoch [7/10], Batch [1/250], Loss: 9.4391, Obj Loss: 0.9230, BBox Loss: 0.0003, Class Loss: 8.5159\n",
            "Epoch [7/10], Batch [11/250], Loss: 8.8256, Obj Loss: 0.6439, BBox Loss: 0.0002, Class Loss: 8.1816\n",
            "Epoch [7/10], Batch [21/250], Loss: 9.5653, Obj Loss: 1.3831, BBox Loss: 0.0003, Class Loss: 8.1818\n",
            "Epoch [7/10], Batch [31/250], Loss: 11.5643, Obj Loss: 1.9381, BBox Loss: 0.0003, Class Loss: 9.6258\n",
            "Epoch [7/10], Batch [41/250], Loss: 11.6422, Obj Loss: 1.0031, BBox Loss: 0.0003, Class Loss: 10.6387\n",
            "Epoch [7/10], Batch [51/250], Loss: 9.0796, Obj Loss: 0.9199, BBox Loss: 0.0003, Class Loss: 8.1593\n",
            "Epoch [7/10], Batch [61/250], Loss: 10.5919, Obj Loss: 2.5871, BBox Loss: 0.0005, Class Loss: 8.0043\n",
            "Epoch [7/10], Batch [71/250], Loss: 7.8251, Obj Loss: 1.1463, BBox Loss: 0.0005, Class Loss: 6.6784\n",
            "Epoch [7/10], Batch [81/250], Loss: 9.6385, Obj Loss: 1.0897, BBox Loss: 0.0003, Class Loss: 8.5485\n",
            "Epoch [7/10], Batch [91/250], Loss: 9.3568, Obj Loss: 1.1639, BBox Loss: 0.0005, Class Loss: 8.1924\n",
            "Epoch [7/10], Batch [101/250], Loss: 10.3375, Obj Loss: 1.7362, BBox Loss: 0.0004, Class Loss: 8.6009\n",
            "Epoch [7/10], Batch [111/250], Loss: 9.9382, Obj Loss: 1.3442, BBox Loss: 0.0004, Class Loss: 8.5935\n",
            "Epoch [7/10], Batch [121/250], Loss: 9.6117, Obj Loss: 1.0372, BBox Loss: 0.0004, Class Loss: 8.5740\n",
            "Epoch [7/10], Batch [131/250], Loss: 10.7455, Obj Loss: 1.3165, BBox Loss: 0.0006, Class Loss: 9.4284\n",
            "Epoch [7/10], Batch [141/250], Loss: 7.8849, Obj Loss: 0.5025, BBox Loss: 0.0007, Class Loss: 7.3816\n",
            "Epoch [7/10], Batch [151/250], Loss: 9.2479, Obj Loss: 1.8043, BBox Loss: 0.0006, Class Loss: 7.4431\n",
            "Epoch [7/10], Batch [161/250], Loss: 8.8777, Obj Loss: 0.8267, BBox Loss: 0.0005, Class Loss: 8.0505\n",
            "Epoch [7/10], Batch [171/250], Loss: 6.9487, Obj Loss: 0.4752, BBox Loss: 0.0006, Class Loss: 6.4728\n",
            "Epoch [7/10], Batch [181/250], Loss: 8.8349, Obj Loss: 0.8762, BBox Loss: 0.0004, Class Loss: 7.9583\n",
            "Epoch [7/10], Batch [191/250], Loss: 9.1627, Obj Loss: 0.6727, BBox Loss: 0.0005, Class Loss: 8.4896\n",
            "Epoch [7/10], Batch [201/250], Loss: 9.3132, Obj Loss: 1.7524, BBox Loss: 0.0005, Class Loss: 7.5603\n",
            "Epoch [7/10], Batch [211/250], Loss: 11.5708, Obj Loss: 2.2149, BBox Loss: 0.0004, Class Loss: 9.3555\n",
            "Epoch [7/10], Batch [221/250], Loss: 9.1753, Obj Loss: 1.3772, BBox Loss: 0.0003, Class Loss: 7.7977\n",
            "Epoch [7/10], Batch [231/250], Loss: 10.8386, Obj Loss: 0.9319, BBox Loss: 0.0003, Class Loss: 9.9064\n",
            "Epoch [7/10], Batch [241/250], Loss: 10.9652, Obj Loss: 1.5683, BBox Loss: 0.0003, Class Loss: 9.3965\n",
            "Epoch [7/10] completed in 645.62s\n",
            "Epoch [8/10], Batch [1/250], Loss: 7.3415, Obj Loss: 2.5663, BBox Loss: 0.0006, Class Loss: 4.7746\n",
            "Epoch [8/10], Batch [11/250], Loss: 12.0985, Obj Loss: 2.4471, BBox Loss: 0.0004, Class Loss: 9.6510\n",
            "Epoch [8/10], Batch [21/250], Loss: 9.3682, Obj Loss: 1.6313, BBox Loss: 0.0007, Class Loss: 7.7361\n",
            "Epoch [8/10], Batch [31/250], Loss: 8.7060, Obj Loss: 0.7883, BBox Loss: 0.0005, Class Loss: 7.9172\n",
            "Epoch [8/10], Batch [41/250], Loss: 10.1126, Obj Loss: 0.8951, BBox Loss: 0.0003, Class Loss: 9.2172\n",
            "Epoch [8/10], Batch [51/250], Loss: 9.4484, Obj Loss: 1.2825, BBox Loss: 0.0003, Class Loss: 8.1656\n",
            "Epoch [8/10], Batch [61/250], Loss: 11.7318, Obj Loss: 1.7225, BBox Loss: 0.0004, Class Loss: 10.0090\n",
            "Epoch [8/10], Batch [71/250], Loss: 10.9646, Obj Loss: 1.2777, BBox Loss: 0.0003, Class Loss: 9.6866\n",
            "Epoch [8/10], Batch [81/250], Loss: 8.8613, Obj Loss: 0.7434, BBox Loss: 0.0002, Class Loss: 8.1176\n",
            "Epoch [8/10], Batch [91/250], Loss: 9.4641, Obj Loss: 0.8577, BBox Loss: 0.0001, Class Loss: 8.6062\n",
            "Epoch [8/10], Batch [101/250], Loss: 15.1482, Obj Loss: 1.3082, BBox Loss: 0.0003, Class Loss: 13.8396\n",
            "Epoch [8/10], Batch [111/250], Loss: 10.8325, Obj Loss: 1.7157, BBox Loss: 0.0003, Class Loss: 9.1165\n",
            "Epoch [8/10], Batch [121/250], Loss: 8.1037, Obj Loss: 0.8454, BBox Loss: 0.0003, Class Loss: 7.2581\n",
            "Epoch [8/10], Batch [131/250], Loss: 9.2121, Obj Loss: 2.2708, BBox Loss: 0.0004, Class Loss: 6.9409\n",
            "Epoch [8/10], Batch [141/250], Loss: 7.7758, Obj Loss: 1.2963, BBox Loss: 0.0003, Class Loss: 6.4792\n",
            "Epoch [8/10], Batch [151/250], Loss: 8.8010, Obj Loss: 0.5367, BBox Loss: 0.0003, Class Loss: 8.2641\n",
            "Epoch [8/10], Batch [161/250], Loss: 11.5169, Obj Loss: 3.4564, BBox Loss: 0.0003, Class Loss: 8.0602\n",
            "Epoch [8/10], Batch [171/250], Loss: 9.6507, Obj Loss: 1.1362, BBox Loss: 0.0002, Class Loss: 8.5143\n",
            "Epoch [8/10], Batch [181/250], Loss: 9.4887, Obj Loss: 1.5239, BBox Loss: 0.0002, Class Loss: 7.9646\n",
            "Epoch [8/10], Batch [191/250], Loss: 8.9606, Obj Loss: 1.4957, BBox Loss: 0.0003, Class Loss: 7.4646\n",
            "Epoch [8/10], Batch [201/250], Loss: 10.0892, Obj Loss: 2.3812, BBox Loss: 0.0003, Class Loss: 7.7077\n",
            "Epoch [8/10], Batch [211/250], Loss: 9.7444, Obj Loss: 1.3889, BBox Loss: 0.0002, Class Loss: 8.3552\n",
            "Epoch [8/10], Batch [221/250], Loss: 10.3185, Obj Loss: 1.7207, BBox Loss: 0.0002, Class Loss: 8.5976\n",
            "Epoch [8/10], Batch [231/250], Loss: 10.4155, Obj Loss: 1.2410, BBox Loss: 0.0002, Class Loss: 9.1743\n",
            "Epoch [8/10], Batch [241/250], Loss: 9.7115, Obj Loss: 2.3210, BBox Loss: 0.0002, Class Loss: 7.3903\n",
            "Epoch [8/10] completed in 621.62s\n",
            "Epoch [9/10], Batch [1/250], Loss: 11.4465, Obj Loss: 1.6723, BBox Loss: 0.0002, Class Loss: 9.7740\n",
            "Epoch [9/10], Batch [11/250], Loss: 8.2883, Obj Loss: 0.8743, BBox Loss: 0.0002, Class Loss: 7.4138\n",
            "Epoch [9/10], Batch [21/250], Loss: 10.3143, Obj Loss: 1.2786, BBox Loss: 0.0003, Class Loss: 9.0354\n",
            "Epoch [9/10], Batch [31/250], Loss: 8.8180, Obj Loss: 0.4394, BBox Loss: 0.0002, Class Loss: 8.3784\n",
            "Epoch [9/10], Batch [41/250], Loss: 7.4256, Obj Loss: 1.9694, BBox Loss: 0.0003, Class Loss: 5.4558\n",
            "Epoch [9/10], Batch [51/250], Loss: 9.0446, Obj Loss: 2.0861, BBox Loss: 0.0003, Class Loss: 6.9582\n",
            "Epoch [9/10], Batch [61/250], Loss: 13.5203, Obj Loss: 2.2777, BBox Loss: 0.0003, Class Loss: 11.2422\n",
            "Epoch [9/10], Batch [71/250], Loss: 9.9250, Obj Loss: 0.8145, BBox Loss: 0.0002, Class Loss: 9.1103\n",
            "Epoch [9/10], Batch [81/250], Loss: 10.0380, Obj Loss: 0.8826, BBox Loss: 0.0002, Class Loss: 9.1552\n",
            "Epoch [9/10], Batch [91/250], Loss: 9.1220, Obj Loss: 1.3069, BBox Loss: 0.0002, Class Loss: 7.8149\n",
            "Epoch [9/10], Batch [101/250], Loss: 5.9767, Obj Loss: 0.8932, BBox Loss: 0.0002, Class Loss: 5.0833\n",
            "Epoch [9/10], Batch [111/250], Loss: 8.7871, Obj Loss: 1.3653, BBox Loss: 0.0001, Class Loss: 7.4217\n",
            "Epoch [9/10], Batch [121/250], Loss: 11.6188, Obj Loss: 1.9377, BBox Loss: 0.0003, Class Loss: 9.6809\n",
            "Epoch [9/10], Batch [131/250], Loss: 10.7475, Obj Loss: 1.6454, BBox Loss: 0.0003, Class Loss: 9.1018\n",
            "Epoch [9/10], Batch [141/250], Loss: 8.6029, Obj Loss: 0.5283, BBox Loss: 0.0002, Class Loss: 8.0744\n",
            "Epoch [9/10], Batch [151/250], Loss: 7.8613, Obj Loss: 0.8379, BBox Loss: 0.0001, Class Loss: 7.0233\n",
            "Epoch [9/10], Batch [161/250], Loss: 8.8095, Obj Loss: 0.7273, BBox Loss: 0.0002, Class Loss: 8.0821\n",
            "Epoch [9/10], Batch [171/250], Loss: 12.3101, Obj Loss: 1.8463, BBox Loss: 0.0002, Class Loss: 10.4637\n",
            "Epoch [9/10], Batch [181/250], Loss: 6.6322, Obj Loss: 1.3832, BBox Loss: 0.0003, Class Loss: 5.2487\n",
            "Epoch [9/10], Batch [191/250], Loss: 10.6260, Obj Loss: 1.9317, BBox Loss: 0.0001, Class Loss: 8.6942\n",
            "Epoch [9/10], Batch [201/250], Loss: 9.9576, Obj Loss: 1.0442, BBox Loss: 0.0002, Class Loss: 8.9133\n",
            "Epoch [9/10], Batch [211/250], Loss: 10.0598, Obj Loss: 1.2134, BBox Loss: 0.0001, Class Loss: 8.8463\n",
            "Epoch [9/10], Batch [221/250], Loss: 9.6426, Obj Loss: 1.9962, BBox Loss: 0.0002, Class Loss: 7.6462\n",
            "Epoch [9/10], Batch [231/250], Loss: 7.9133, Obj Loss: 1.0974, BBox Loss: 0.0002, Class Loss: 6.8157\n",
            "Epoch [9/10], Batch [241/250], Loss: 9.0002, Obj Loss: 1.9574, BBox Loss: 0.0002, Class Loss: 7.0427\n",
            "Epoch [9/10] completed in 650.00s\n",
            "Epoch [10/10], Batch [1/250], Loss: 9.2380, Obj Loss: 0.5901, BBox Loss: 0.0001, Class Loss: 8.6477\n",
            "Epoch [10/10], Batch [11/250], Loss: 9.6760, Obj Loss: 1.1245, BBox Loss: 0.0002, Class Loss: 8.5514\n",
            "Epoch [10/10], Batch [21/250], Loss: 9.4150, Obj Loss: 1.0259, BBox Loss: 0.0001, Class Loss: 8.3890\n",
            "Epoch [10/10], Batch [31/250], Loss: 9.5216, Obj Loss: 0.4252, BBox Loss: 0.0002, Class Loss: 9.0962\n",
            "Epoch [10/10], Batch [41/250], Loss: 9.1584, Obj Loss: 1.3822, BBox Loss: 0.0002, Class Loss: 7.7760\n",
            "Epoch [10/10], Batch [51/250], Loss: 6.7573, Obj Loss: 1.3840, BBox Loss: 0.0002, Class Loss: 5.3731\n",
            "Epoch [10/10], Batch [61/250], Loss: 9.1805, Obj Loss: 0.9236, BBox Loss: 0.0001, Class Loss: 8.2568\n",
            "Epoch [10/10], Batch [71/250], Loss: 8.7780, Obj Loss: 0.8925, BBox Loss: 0.0002, Class Loss: 7.8854\n",
            "Epoch [10/10], Batch [81/250], Loss: 10.3821, Obj Loss: 1.2383, BBox Loss: 0.0001, Class Loss: 9.1436\n",
            "Epoch [10/10], Batch [91/250], Loss: 9.6920, Obj Loss: 1.2608, BBox Loss: 0.0001, Class Loss: 8.4311\n",
            "Epoch [10/10], Batch [101/250], Loss: 9.3345, Obj Loss: 2.2302, BBox Loss: 0.0001, Class Loss: 7.1042\n",
            "Epoch [10/10], Batch [111/250], Loss: 9.0132, Obj Loss: 0.9214, BBox Loss: 0.0001, Class Loss: 8.0916\n",
            "Epoch [10/10], Batch [121/250], Loss: 8.2750, Obj Loss: 1.3348, BBox Loss: 0.0001, Class Loss: 6.9401\n",
            "Epoch [10/10], Batch [131/250], Loss: 11.3158, Obj Loss: 2.7632, BBox Loss: 0.0002, Class Loss: 8.5524\n",
            "Epoch [10/10], Batch [141/250], Loss: 7.9192, Obj Loss: 0.7868, BBox Loss: 0.0001, Class Loss: 7.1322\n",
            "Epoch [10/10], Batch [151/250], Loss: 8.5859, Obj Loss: 1.3809, BBox Loss: 0.0002, Class Loss: 7.2048\n",
            "Epoch [10/10], Batch [161/250], Loss: 8.9662, Obj Loss: 1.3554, BBox Loss: 0.0002, Class Loss: 7.6107\n",
            "Epoch [10/10], Batch [171/250], Loss: 9.4317, Obj Loss: 0.9785, BBox Loss: 0.0001, Class Loss: 8.4531\n",
            "Epoch [10/10], Batch [181/250], Loss: 8.4673, Obj Loss: 2.2188, BBox Loss: 0.0001, Class Loss: 6.2484\n",
            "Epoch [10/10], Batch [191/250], Loss: 11.5430, Obj Loss: 1.7058, BBox Loss: 0.0001, Class Loss: 9.8371\n",
            "Epoch [10/10], Batch [201/250], Loss: 8.7209, Obj Loss: 1.3093, BBox Loss: 0.0001, Class Loss: 7.4114\n",
            "Epoch [10/10], Batch [211/250], Loss: 9.6371, Obj Loss: 1.5398, BBox Loss: 0.0001, Class Loss: 8.0972\n",
            "Epoch [10/10], Batch [221/250], Loss: 8.3312, Obj Loss: 1.1471, BBox Loss: 0.0001, Class Loss: 7.1840\n",
            "Epoch [10/10], Batch [231/250], Loss: 9.4157, Obj Loss: 1.8854, BBox Loss: 0.0001, Class Loss: 7.5302\n",
            "Epoch [10/10], Batch [241/250], Loss: 8.9093, Obj Loss: 1.1699, BBox Loss: 0.0001, Class Loss: 7.7392\n",
            "Epoch [10/10] completed in 631.75s\n"
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize dataset and dataloader\n",
        "dataset = HelloWorldDataset('/home/krishna/Documents/Niqo_Robotics/Font_Detection/annotations.csv', transform=transform)\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=4,  # Increase batch size if possible\n",
        "    shuffle=True,\n",
        "    num_workers=4,  # Adjust based on your system\n",
        "    collate_fn=lambda x: tuple(zip(*x))\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "scales = [32, 64, 128]  \n",
        "ratios = [0.5, 1.0, 2.0]\n",
        "num_anchors_per_location = len(scales) * len(ratios)\n",
        "num_classes = len(dataset.fonts)\n",
        "model = HelloWorldDetector(num_classes=num_classes, num_anchors_per_location=num_anchors_per_location)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define optimizer and loss functions\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    for batch_idx, (images, targets) in enumerate(dataloader):\n",
        "        images = torch.stack(images).to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        objectness, bbox_deltas, font_scores = model(images)\n",
        "\n",
        "        # Generate anchors\n",
        "        _, _, feature_height, feature_width = objectness.shape\n",
        "        anchors = generate_anchors((feature_height, feature_width), scales=scales, ratios=ratios)\n",
        "        anchors = anchors.to(device)\n",
        "\n",
        "        total_obj_loss = 0\n",
        "        total_bbox_loss = 0\n",
        "        total_class_loss = 0\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            gt_boxes = targets[i]['boxes'].to(device)\n",
        "            gt_labels = targets[i]['labels'].to(device)\n",
        "\n",
        "            # Reshape objectness and bbox_deltas\n",
        "            obj_pred = objectness[i].permute(1, 2, 0).reshape(-1)\n",
        "            bbox_pred = bbox_deltas[i].permute(1, 2, 0).reshape(-1, 4)\n",
        "\n",
        "            # Assign labels and targets\n",
        "            labels, bbox_targets = assign_labels(anchors, gt_boxes, gt_labels)\n",
        "            labels = labels.to(device)\n",
        "            bbox_targets = bbox_targets.to(device)\n",
        "\n",
        "            # Objectness loss\n",
        "            obj_target = (labels >= 0).float()\n",
        "            obj_loss = F.binary_cross_entropy(obj_pred, obj_target)\n",
        "\n",
        "            # Bounding box regression loss\n",
        "            positive_indices = labels >= 0\n",
        "            if positive_indices.sum() > 0:\n",
        "                bbox_loss = F.smooth_l1_loss(bbox_pred[positive_indices], bbox_targets[positive_indices])\n",
        "            else:\n",
        "                bbox_loss = torch.tensor(0.0).to(device)\n",
        "\n",
        "            # Font classification loss\n",
        "            font_score = font_scores[i].unsqueeze(0)  # [1, num_classes]\n",
        "            class_loss = F.cross_entropy(font_score, gt_labels[0].unsqueeze(0))\n",
        "\n",
        "            total_obj_loss += obj_loss\n",
        "            total_bbox_loss += bbox_loss\n",
        "            total_class_loss += class_loss\n",
        "\n",
        "        total_loss = total_obj_loss + total_bbox_loss + total_class_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], \"\n",
        "                  f\"Loss: {total_loss.item():.4f}, Obj Loss: {total_obj_loss.item():.4f}, \"\n",
        "                  f\"BBox Loss: {total_bbox_loss.item():.4f}, Class Loss: {total_class_loss.item():.4f}\")\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {epoch_end_time - epoch_start_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0isfNe-2aHLG"
      },
      "source": [
        "**INFERENCE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "8zCs22RlaGrN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes:\n",
            "objectness shape: torch.Size([1, 9, 32, 32])\n",
            "bbox_deltas shape: torch.Size([1, 36, 32, 32])\n",
            "font_scores shape: torch.Size([1, 10])\n",
            "Feature map size: 32 x 32\n",
            "Number of anchors per location: 9\n",
            "Total anchors: 9216\n",
            "After reshaping:\n",
            "objectness shape: (9216,)\n",
            "bbox_deltas shape: (9216, 4)\n",
            "font_probs shape: (9216, 10)\n",
            "indices shape: (9216,)\n",
            "Number of detections: 9216\n",
            "Predicted fonts: [4 4 4 ... 4 4 4]\n",
            "Predicted confidences: [0.17877178 0.17877178 0.17877178 ... 0.17877178 0.17877178 0.17877178]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Load and preprocess the test image\n",
        "test_image = Image.open('/home/krishna/Documents/Niqo_Robotics/Font_Detection/image_2.png').convert('RGB')\n",
        "input_image = transform(test_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "with torch.no_grad():\n",
        "    objectness, bbox_deltas, font_scores = model(input_image)\n",
        "\n",
        "print(\"Original shapes:\")\n",
        "print(\"objectness shape:\", objectness.shape)\n",
        "print(\"bbox_deltas shape:\", bbox_deltas.shape)\n",
        "print(\"font_scores shape:\", font_scores.shape)\n",
        "\n",
        "# Extract dimensions\n",
        "batch_size = objectness.shape[0]\n",
        "num_anchors_per_location = objectness.shape[1]  # Should be 1 if only one anchor per location\n",
        "feature_height, feature_width = objectness.shape[2], objectness.shape[3]\n",
        "num_classes = font_scores.shape[1]\n",
        "\n",
        "total_anchors = batch_size * num_anchors_per_location * feature_height * feature_width\n",
        "\n",
        "print(f\"Feature map size: {feature_height} x {feature_width}\")\n",
        "print(f\"Number of anchors per location: {num_anchors_per_location}\")\n",
        "print(f\"Total anchors: {total_anchors}\")\n",
        "\n",
        "# Reshape objectness\n",
        "objectness = objectness.permute(0, 2, 3, 1).reshape(-1)\n",
        "objectness = objectness.cpu().numpy()\n",
        "\n",
        "# Reshape bbox_deltas\n",
        "bbox_deltas = bbox_deltas.view(batch_size, num_anchors_per_location, 4, feature_height, feature_width)\n",
        "bbox_deltas = bbox_deltas.permute(0, 3, 4, 1, 2).reshape(-1, 4)\n",
        "bbox_deltas = bbox_deltas.cpu().numpy()\n",
        "\n",
        "# Process font_probs\n",
        "font_probs = nn.Softmax(dim=1)(font_scores)  # Shape: [batch_size, num_classes]\n",
        "font_probs = font_probs.unsqueeze(1).repeat(1, feature_height * feature_width * num_anchors_per_location, 1)\n",
        "font_probs = font_probs.view(-1, num_classes)\n",
        "font_probs = font_probs.cpu().numpy()\n",
        "\n",
        "print(\"After reshaping:\")\n",
        "print(f\"objectness shape: {objectness.shape}\")\n",
        "print(f\"bbox_deltas shape: {bbox_deltas.shape}\")\n",
        "print(f\"font_probs shape: {font_probs.shape}\")\n",
        "print(f\"indices shape: {indices.shape}\")\n",
        "\n",
        "# Threshold objectness scores\n",
        "threshold = 0.5\n",
        "indices = objectness > threshold  # Shape: [batch_size * total_anchors]\n",
        "\n",
        "# Get bounding boxes and font predictions\n",
        "pred_boxes = bbox_deltas[indices]\n",
        "pred_fonts = font_probs.argmax(axis=1)[indices]\n",
        "pred_confidences = font_probs.max(axis=1)[indices]\n",
        "\n",
        "print(\"Number of detections:\", len(pred_boxes))\n",
        "print(\"Predicted fonts:\", pred_fonts)\n",
        "print(\"Predicted confidences:\", pred_confidences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW25e8SCaLTa"
      },
      "source": [
        "**VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "usr_X2P9aNKU"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(test_image)\n",
        "\n",
        "for bbox, font_idx, confidence in zip(pred_boxes, pred_fonts, pred_confidences):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    width, height = x_max - x_min, y_max - y_min\n",
        "    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    # Add font label and confidence\n",
        "    font_name = fonts[font_idx]\n",
        "    ax.text(x_min, y_min - 10, f\"{font_name} ({confidence*100:.1f}%)\", color='red', fontsize=12, weight='bold')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
